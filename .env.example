# This file contains the environment variables needed by the backend server.
# Copy this file to .env and fill in your actual API details.

# You can define multiple LLM "experts" by following the pattern:
# LLM_[INDEX]_NAME, LLM_[INDEX]_ENDPOINT, LLM_[INDEX]_KEY
# The NAME will be shown in the UI dropdowns.

# Expert 1 (e.g., a local model)
LLM_1_NAME="Local Llama3"
LLM_1_ENDPOINT="http://localhost:11434/v1/chat/completions"
LLM_1_KEY="ollama"
# The actual model name the API expects (e.g., 'llama3'). Defaults to the NAME if not set.
LLM_1_MODEL_NAME="llama3"

# Expert 2 (e.g., OpenAI's GPT-4) - uncomment and configure to use
# LLM_2_NAME="OpenAI GPT-4"
# LLM_2_ENDPOINT="https://api.openai.com/v1/chat/completions"
# LLM_2_KEY="sk-your-openai-api-key"
# LLM_2_MODEL_NAME="gpt-4-turbo"

# SAM.gov API Key for Opportunity Search
SAM_API_KEY="your-sam-gov-api-key-here"
